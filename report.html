
<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="x-ua-compatible" content="IE=9">

    <title>COURSERA PRACTICAL MACHINE LEARNING COURSE PROJECT</title>

    <style type="text/css">
        body, td {
            font-family: sans-serif;
            background-color: white;
            font-size: 12px;
            margin: 8px;
        }

        tt, code, pre {
            font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
        }

        h1 {
            font-size: 2.2em;
        }

        h2 {
            font-size: 1.8em;
        }

        h3 {
            font-size: 1.4em;
        }

        h4 {
            font-size: 1.0em;
        }

        h5 {
            font-size: 0.9em;
        }

        h6 {
            font-size: 0.8em;
        }

        a:visited {
            color: rgb(50%, 0%, 50%);
        }

        pre {
            margin-top: 0;
            max-width: 95%;
            border: 1px solid #ccc;
            white-space: pre-wrap;
        }

            pre code {
                display: block;
                padding: 0.5em;
            }

        code.r, code.cpp {
            background-color: #F8F8F8;
        }

        table, td, th {
            border: none;
        }

        blockquote {
            color: #666666;
            margin: 0;
            padding-left: 1em;
            border-left: 0.5em #EEE solid;
        }

        hr {
            height: 0px;
            border-bottom: none;
            border-top-width: thin;
            border-top-style: dotted;
            border-top-color: #999999;
        }

        @media print {
            * {
                background: transparent !important;
                color: black !important;
                filter: none !important;
                -ms-filter: none !important;
            }

            body {
                font-size: 12pt;
                max-width: 100%;
            }

            a, a:visited {
                text-decoration: underline;
            }

            hr {
                visibility: hidden;
                page-break-before: always;
            }

            pre, blockquote {
                padding-right: 1em;
                page-break-inside: avoid;
            }

            tr, img {
                page-break-inside: avoid;
            }

            img {
                max-width: 100% !important;
            }

            @page :left {
                margin: 15mm 20mm 15mm 10mm;
            }

            @page :right {
                margin: 15mm 10mm 15mm 20mm;
            }

            p, h2, h3 {
                orphans: 3;
                widows: 3;
            }

            h2, h3 {
                page-break-after: avoid;
            }
        }
    </style>

    <!-- Styles for R syntax highlighter -->
    <style type="text/css">
        pre .operator,
        pre .paren {
            color: rgb(104, 118, 135);
        }

        pre .literal {
            color: rgb(88, 72, 246);
        }

        pre .number {
            color: rgb(0, 0, 205);
        }

        pre .comment {
            color: rgb(76, 136, 107);
        }

        pre .keyword {
            color: rgb(0, 0, 255);
        }

        pre .identifier {
            color: rgb(0, 0, 0);
        }

        pre .string {
            color: rgb(3, 106, 7);
        }
    </style>

    <!-- R syntax highlighter -->
    <script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
    </script>




</head>

<body>
    <h1>COURSERA PRACTICAL MACHINE LEARNING COURSE PROJECT</h1>

    <h2>Overview</h2>

    <p>This report is submitted for Coursera Practical Machine Learning course Peer Assessed Project. The goal of the project is to use accelerometers data to predict how health participants performed a unilateral dumbbell bicep curl exercise. The analysis is done using the caret package.</p>

    <h2>The Data</h2>

    <p><em>Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human &#39;13) . Stuttgart, Germany: ACM SIGCHI, 2013.</em></p>

    <p>Dataset description from the authors’:

    <p> “Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).</p>
    <p>       Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. Participants were supervised by an experienced weight lifter to make sure the execution complied to the manner they were supposed to simulate.    </p>

    <h2> The Challenge </h2>

    <P>By using data gathered from accelerometers on the belt, forearm, arm, and dumbbell of the 6 health participants, build a a machine learning algorithm in order to predict the appropriate activity quality (class A-E)?</P>

    <h2>Getting and cleaning data</h2>

    <h2>loading the data from url</h2>
    <pre><code class="r">
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
    </code></pre>

    <h2>removing columns with NA values</h2>

<pre><code class="r">
dataCounts <- function(x) {
    as.vector(apply(x, 2, function(x) length(which(!is.na(x)))))
}

dataCnts <- dataCounts(training)

colsToRemove <- c()

for (cnt in 1:160) {
    if (colcnts[cnt] < nrow(training)) {
        colsToRemove <- c(drops, colnames(training)[cnt])
    }
}

training <- training[,!(names(training) %in% drops)]
testing <- testing[,!(names(testing) %in% drops)]

#Removing identifier columns
training <- training[, -c(1,3,4,5,6,7)]
testing <- testing[, -c(1,3,4,5,6,7)]

</code></pre>

    <h2>Non zero varience</h2>
    <p> after the previous step, i tested for nonZeroVarience but it turns out it is unnseccery to remove more columns due to invariability</p>
    
    <pre><code class="r">
                      freqRatio percentUnique zeroVar   nzv
 roll_belt                1.102       6.77811   FALSE FALSE
 pitch_belt               1.036       9.37723   FALSE FALSE
 yaw_belt                 1.058       9.97350   FALSE FALSE
 total_accel_belt         1.063       0.14779   FALSE FALSE
 gyros_belt_x             1.059       0.71348   FALSE FALSE
 gyros_belt_y             1.144       0.35165   FALSE FALSE
 gyros_belt_z             1.066       0.86128   FALSE FALSE
 accel_belt_x             1.055       0.83580   FALSE FALSE
 accel_belt_y             1.114       0.72877   FALSE FALSE
 accel_belt_z             1.079       1.52380   FALSE FALSE
 magnet_belt_x            1.090       1.66650   FALSE FALSE
 magnet_belt_y            1.100       1.51870   FALSE FALSE
 magnet_belt_z            1.006       2.32902   FALSE FALSE
 roll_arm                52.338      13.52563   FALSE FALSE
 pitch_arm               87.256      15.73234   FALSE FALSE
 yaw_arm                 33.029      14.65702   FALSE FALSE
 total_accel_arm          1.025       0.33636   FALSE FALSE
 gyros_arm_x              1.016       3.27693   FALSE FALSE
 gyros_arm_y              1.454       1.91622   FALSE FALSE
 gyros_arm_z              1.111       1.26389   FALSE FALSE
 accel_arm_x              1.017       3.95984   FALSE FALSE
 accel_arm_y              1.140       2.73672   FALSE FALSE
 accel_arm_z              1.128       4.03629   FALSE FALSE
 magnet_arm_x             1.000       6.82397   FALSE FALSE
 magnet_arm_y             1.057       4.44399   FALSE FALSE
 magnet_arm_z             1.036       6.44685   FALSE FALSE
 roll_dumbbell            1.022      83.78351   FALSE FALSE
 pitch_dumbbell           2.277      81.22516   FALSE FALSE
 yaw_dumbbell             1.132      83.14137   FALSE FALSE
 total_accel_dumbbell     1.073       0.21914   FALSE FALSE
 gyros_dumbbell_x         1.003       1.22821   FALSE FALSE
 gyros_dumbbell_y         1.265       1.41678   FALSE FALSE
 gyros_dumbbell_z         1.060       1.04984   FALSE FALSE
 accel_dumbbell_x         1.018       2.16594   FALSE FALSE
 accel_dumbbell_y         1.053       2.37489   FALSE FALSE
 accel_dumbbell_z         1.133       2.08949   FALSE FALSE
 magnet_dumbbell_x        1.098       5.74865   FALSE FALSE
 magnet_dumbbell_y        1.198       4.30129   FALSE FALSE
 magnet_dumbbell_z        1.021       3.44511   FALSE FALSE
 roll_forearm            11.589      11.08959   FALSE FALSE
 pitch_forearm           65.983      14.85577   FALSE FALSE
 yaw_forearm             15.323      10.14677   FALSE FALSE
 total_accel_forearm      1.129       0.35674   FALSE FALSE
 gyros_forearm_x          1.059       1.51870   FALSE FALSE
 gyros_forearm_y          1.037       3.77637   FALSE FALSE
 gyros_forearm_z          1.123       1.56457   FALSE FALSE
 accel_forearm_x          1.126       4.04648   FALSE FALSE
 accel_forearm_y          1.059       5.11161   FALSE FALSE
 accel_forearm_z          1.006       2.95587   FALSE FALSE
 magnet_forearm_x         1.012       7.76679   FALSE FALSE
 magnet_forearm_y         1.247       9.54031   FALSE FALSE
 magnet_forearm_z         1.000       8.57711   FALSE FALSE
 classe                   1.470       0.02548   FALSE FALSE
        </code></pre>

<h2>splitting the data into training and validation sets</h2>
    <p>Since the data set is big enough and in order to determine the out of sample error, i decided to split the training data set into training and validation data set</p>
<pre><code class="r">
inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
TrainSet <- training[inTrain, ]
TestSet  <- training[-inTrain, ]
</code></pre>

<h2>Building Models</h2>

    <h2>Classification Tree</h2>
    <p>I decided to start with a classification tree with the train function without cross validation and then test the model with the validation set</p>
<pre><code class="r">
modFitDecTree <- train(classe ~ ., data=TrainSet, method="rpart")
predictDecTree <- predict(modFitDecTree, newdata=TestSet)
confMatDecTree <- confusionMatrix(predictDecTree, TestSet$classe)
confMatDecTree
</code></pre>

<p>The following results shows a very poor performance with a 0.4867 accurecy</p>
<pre><code class="r">
         Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 1508  491  474  422  166
         B   28  365   31  181  158
         C  134  283  521  361  288
         D    0    0    0    0    0
         E    4    0    0    0  470
Overall Statistics
               Accuracy : 0.4867
                 95% CI : (0.4738, 0.4995)
    No Information Rate : 0.2845
    P-Value [Acc > NIR] : < 2.2e-16
                  Kappa : 0.3291
 Mcnemar's Test P-Value : NA
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9008  0.32046  0.50780   0.0000  0.43438
Specificity            0.6312  0.91614  0.78061   1.0000  0.99917
Pos Pred Value         0.4926  0.47837  0.32829      NaN  0.99156
Neg Pred Value         0.9412  0.84889  0.88250   0.8362  0.88690
Prevalence             0.2845  0.19354  0.17434   0.1638  0.18386
Detection Rate         0.2562  0.06202  0.08853   0.0000  0.07986
Detection Prevalence   0.5201  0.12965  0.26967   0.0000  0.08054
Balanced Accuracy      0.7660  0.61830  0.64421   0.5000  0.71677

</code></pre>

<h2>Classification Tree with cross validation</h2>
<p>I decided to use cross validation hoping for an imporved perfomance</p>
<pre><code class="r">
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modFitDecTreeCV <- train(classe ~ ., data=TrainSet, method="rpart",trControl=controlRF)
predictDecTreeCV <- predict(modFitDecTreeCV, newdata=TestSet)
confMatDecTreeCV <- confusionMatrix(predictDecTreeCV, TestSet$classe)
confMatDecTreeCV
</code></pre>

    <p>Perfomance improved slightly to  0.4904  </p>

<pre><code class="r">
Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 1529  507  465  429  159
         B   26  346   28  172  153
         C  114  286  533  363  292
         D    0    0    0    0    0
         E    5    0    0    0  478
Overall Statistics
                                          
               Accuracy : 0.4904          
                 95% CI : (0.4775, 0.5033)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.3336          
 Mcnemar's Test P-Value : NA              
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9134  0.30378  0.51949   0.0000  0.44177
Specificity            0.6295  0.92014  0.78288   1.0000  0.99896
Pos Pred Value         0.4950  0.47724  0.33564      NaN  0.98965
Neg Pred Value         0.9481  0.84632  0.88527   0.8362  0.88819
Prevalence             0.2845  0.19354  0.17434   0.1638  0.18386
Detection Rate         0.2598  0.05879  0.09057   0.0000  0.08122
Detection Prevalence   0.5249  0.12319  0.26984   0.0000  0.08207
Balanced Accuracy      0.7715  0.61196  0.65119   0.5000  0.72037
</code></pre>



<h2>Decision tree with cross validation and pre processing</h2>
<p>Next I tried to include pre-processing but it had no effect on performance</p>
<pre><code class="r">
modFitDecTreeCVPP <- train(classe ~ ., data=TrainSet, method="rpart" , preProcess=c("center", "scale" ),trControl=controlRF)>    
predictDecTreeCVPP <- predict(modFitDecTreeCVPP, newdata=TestSet)>    
confMatDecTreeCVPP <- confusionMatrix(predictDecTreeCVPP, TestSet$classe)>    
confMatDecTreeCVPP
                      </code></pre>
    <pre><code class="r">
Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 1529  507  465  429  159
         B   26  346   28  172  153
         C  114  286  533  363  292
         D    0    0    0    0    0
         E    5    0    0    0  478
Overall Statistics
                                          
               Accuracy : 0.4904          
                 95% CI : (0.4775, 0.5033)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.3336          
 Mcnemar's Test P-Value : NA              
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9134  0.30378  0.51949   0.0000  0.44177
Specificity            0.6295  0.92014  0.78288   1.0000  0.99896
Pos Pred Value         0.4950  0.47724  0.33564      NaN  0.98965
Neg Pred Value         0.9481  0.84632  0.88527   0.8362  0.88819
Prevalence             0.2845  0.19354  0.17434   0.1638  0.18386
Detection Rate         0.2598  0.05879  0.09057   0.0000  0.08122
Detection Prevalence   0.5249  0.12319  0.26984   0.0000  0.08207
Balanced Accuracy      0.7715  0.61196  0.65119   0.5000  0.72037
        </code></pre>

<h2>Using the rpart function</h2>
<p>I tried training the model by running the rpart function directly, and sureprisingly perofmance increased to 0.7193</p> 
    <pre><code class="r">
modFitDecTree <- modFitDecTree <- rpart(classe ~ ., data=TrainSet, method="class")
predictDecTree <- predict(modFitDecTree, newdata=TestSet)
confMatDecTree <- confusionMatrix(predictDecTree, TestSet$classe)
confMatDecTree
                     </code></pre>
<pre><code class="r">
Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 1530  270   29  135   66
         B   34  519   41   20   55
         C   29  143  816  141  127
         D   56   66   74  594   60
         E   25  141   66   74  774
Overall Statistics
                                          
               Accuracy : 0.7193          
                 95% CI : (0.7076, 0.7307)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6425          
 Mcnemar's Test P-Value : < 2.2e-16       
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9140  0.45566   0.7953   0.6162   0.7153
Specificity            0.8813  0.96839   0.9094   0.9480   0.9363
Pos Pred Value         0.7537  0.77578   0.6497   0.6988   0.7167
Neg Pred Value         0.9626  0.88113   0.9546   0.9265   0.9359
Prevalence             0.2845  0.19354   0.1743   0.1638   0.1839
Detection Rate         0.2600  0.08819   0.1387   0.1009   0.1315
Detection Prevalence   0.3449  0.11368   0.2134   0.1444   0.1835
Balanced Accuracy      0.8976  0.71203   0.8524   0.7821   0.8258    
    </code></pre>
<h2>Random forest without cross validation</h2>
<p>After the poor performance of Decision trees i Decided to train the model using Random Forest Trees</p>
<pre><code class="r">
    
modFitRandForest <- train(classe ~ ., data=TrainSet, method="rf")
predictRandForest <- predict(modFitRandForest, newdata=TestSet)
confMatRandForest <- confusionMatrix(predictRandForest, TestSet$classe)
confMatRandForest
</code></pre>

<p>This has resulted in a great performance of 0.9913. However, the processing time is very taxing</p>

<pre><code class="r">
Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 1672   11    0    0    0
         B    1 1124    3    0    1
         C    0    4 1019   16    5
         D    0    0    4  946    3
         E    1    0    0    2 1073
Overall Statistics
                                          
               Accuracy : 0.9913          
                 95% CI : (0.9886, 0.9935)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.989           
 Mcnemar's Test P-Value : NA              
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9988   0.9868   0.9932   0.9813   0.9917
Specificity            0.9974   0.9989   0.9949   0.9986   0.9994
Pos Pred Value         0.9935   0.9956   0.9761   0.9927   0.9972
Neg Pred Value         0.9995   0.9968   0.9986   0.9964   0.9981
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2841   0.1910   0.1732   0.1607   0.1823
Detection Prevalence   0.2860   0.1918   0.1774   0.1619   0.1828
Balanced Accuracy      0.9981   0.9929   0.9940   0.9900   0.9955
        </code></pre>

<h2>Random forest with cross validation</h2>
<p>I then used cross validation which resluted in improving the performance from 0.9913 to 0.9915</p>
<pre><code class="r">
controlRF <- trainControl(method="cv" , number=3, verboseIter=FALSE)
modFitRandForest <- train(classe ~ ., data=TrainSet, method="rf",trControl=controlRF)
predictRandForest <- predict(modFitRandForest, newdata=TestSet)
confMatRandForest <- confusionMatrix(predictRandForest, TestSet$classe)
confMatRandForest
</code></pre>

<pre><code class="r">
Confusion Matrix and Statistics
          Reference
Prediction    A    B    C    D    E
         A 1672   10    0    0    0
         B    1 1125    3    0    1
         C    0    4 1018   16    5
         D    0    0    5  947    3
         E    1    0    0    1 1073
Overall Statistics

               Accuracy : 0.9915
                 95% CI : (0.9888, 0.9937)
    No Information Rate : 0.2845
    P-Value [Acc > NIR] : < 2.2e-16

                  Kappa : 0.9893
 Mcnemar's Test P-Value : NA
Statistics by Class:
                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9988   0.9877   0.9922   0.9824   0.9917
Specificity            0.9976   0.9989   0.9949   0.9984   0.9996
Pos Pred Value         0.9941   0.9956   0.9760   0.9916   0.9981
Neg Pred Value         0.9995   0.9971   0.9983   0.9966   0.9981
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2841   0.1912   0.1730   0.1609   0.1823
Detection Prevalence   0.2858   0.1920   0.1772   0.1623   0.1827
Balanced Accuracy      0.9982   0.9933   0.9935   0.9904   0.9956
</pre></code>


<p>Finally, the choosen model "Random Forest with Cross Validation" needs to run on the test data to predict the outcome of 20 different test cases. I ran the model and submitted the results throught the quiz.</p>

    <h2>Out of sample error</h2>
    <ul>
        <li>Decision Tree (using train function, no cross validation or pre-preocessing)        0.4867 = 0.5133</li>
        <li>Decision Tree (using train function, with cross validation)                         0.4904 = 0.5096</li>
        <li>Decision Tree (using train function, with cross validation and pre-preocessing)     0.4904 = 0.5096</li>
        <li>Decision Tree (using rpart function, no cross validation or pre-preocessing)        0.7193 = 0.2807</li>
        <li>Random Forest (no cross validation)                                                 0.9913 = 0.0087</li>
        <li>Random Forest (cross validation)                                                    0.9915 = 0.0085</li>
    </ul>

</body>

</html>
